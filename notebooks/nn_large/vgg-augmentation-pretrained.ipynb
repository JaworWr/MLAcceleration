{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "precise-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "\n",
    "from nn_extrapolation import AcceleratedSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "automotive-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_fn = nn.NLLLoss(reduction=\"sum\")\n",
    "\n",
    "def validation(model, loader):\n",
    "    ok = 0\n",
    "    loss_sum = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss_sum += val_loss_fn(out, y).item()\n",
    "            preds = out.argmax(1)\n",
    "            ok += (preds == y).sum().item()\n",
    "            total += len(y)\n",
    "    return ok / total, loss_sum / total\n",
    "\n",
    "def train_epoch(loss_log):\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        loss_log += list(loss.flatten().cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extra-ottawa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "augmentation = transforms.RandomAffine(10, scale=(0.9, 1.1), translate=(0.2, 0.2))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "rescale = transforms.Resize((224, 224))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    rescale,\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(\"/tmp/i291318/CIFAR\", \n",
    "                            download=True, train=True, transform=transforms.Compose([augmentation, transform]))\n",
    "valid_ds = datasets.CIFAR10(\"/tmp/i291318/CIFAR\", download=True, train=True, transform=transform)\n",
    "test_ds = datasets.CIFAR10(\"/tmp/i291318/CIFAR\", download=True, train=False, transform=transform)\n",
    "\n",
    "train_indices, valid_indices = train_test_split(np.arange(len(train_ds)), test_size=0.2)\n",
    "train_ds = data.Subset(train_ds, train_indices)\n",
    "valid_ds = data.Subset(valid_ds, valid_indices)\n",
    "\n",
    "train_loader = data.DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=8)\n",
    "valid_loader = data.DataLoader(valid_ds, batch_size=64, shuffle=False, num_workers=8)\n",
    "test_loader = data.DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "another-delicious",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "    (7): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 10),\n",
    "    nn.LogSoftmax(-1),\n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gross-deadline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079b2ccf32d548a198bae408584828e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0955, 2.307448388671875)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stock-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = open(\"vgg_log_augmentation_pretrained.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-teens",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "structured-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AcceleratedSGD(model.classifier.parameters(), 1e-3, k=10, momentum=0.9, weight_decay=1e-5, lambda_=1e-8)\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-comparative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba024dffa624b08bae0f28b6f1c15c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.3338\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8abbc881684020b66c37b0843f3147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.7879, validation loss: 0.6028\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a4df760b2948c3974c1d9b9cae6b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.7743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800791c036c54f7c9f3f117427cfcb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.8290, validation loss: 0.4889\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eab12631fc94ddf8c324565f451d67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch\", epoch+1)\n",
    "    loss_log = []\n",
    "    train_epoch(loss_log)\n",
    "    print(f\"Training loss: {np.mean(loss_log):.4f}\")\n",
    "    optimizer.finish_epoch()\n",
    "    val_acc, val_loss = validation(model, valid_loader)\n",
    "    print(f\"Validation accuracy: {val_acc:.4f}, validation loss: {val_loss:.4f}\")\n",
    "    print(\"Epoch\", epoch+1, \n",
    "          f\"Training loss: {np.mean(loss_log):.4f}, validation accuracy: {val_acc:.4f}, validation loss: {val_loss:.4f}\",\n",
    "          file=log_file, flush=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = validation(model, train_loader)\n",
    "valid_score = validation(model, valid_loader)\n",
    "print(\"Train:\", train_score)\n",
    "print(\"Valid:\", valid_score)\n",
    "print(\"Train:\", train_score, flush=True, file=log_file)\n",
    "print(\"Valid:\", valid_score, flush=True, file=log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "model_acc = deepcopy(model)\n",
    "optimizer.accelerate()\n",
    "optimizer.store_parameters([model_acc.classifier.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc.cuda()\n",
    "train_score = validation(model_acc, train_loader)\n",
    "valid_score = validation(model_acc, valid_loader)\n",
    "model_acc.cpu()\n",
    "\n",
    "print(\"Train:\", train_score)\n",
    "print(\"Valid:\", valid_score)\n",
    "print(\"Train:\", train_score, flush=True, file=log_file)\n",
    "print(\"Valid:\", valid_score, flush=True, file=log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-convertible",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.add_param_group({\n",
    "    \"params\": model.features.parameters(),\n",
    "    \"lr\": 1e-4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch\", epoch+1)\n",
    "    loss_log = []\n",
    "    train_epoch(loss_log)\n",
    "    print(f\"Training loss: {np.mean(loss_log):.4f}\")\n",
    "    optimizer.finish_epoch()\n",
    "    val_acc, val_loss = validation(model, valid_loader)\n",
    "    print(f\"Validation accuracy: {val_acc:.4f}, validation loss: {val_loss:.4f}\")\n",
    "    print(\"Epoch\", epoch+1, \n",
    "          f\"Training loss: {np.mean(loss_log):.4f}, validation accuracy: {val_acc:.4f}, validation loss: {val_loss:.4f}\",\n",
    "          file=log_file, flush=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = validation(model, train_loader)\n",
    "valid_score = validation(model, valid_loader)\n",
    "print(\"Train:\", train_score)\n",
    "print(\"Valid:\", valid_score)\n",
    "print(\"Train:\", train_score, flush=True, file=log_file)\n",
    "print(\"Valid:\", valid_score, flush=True, file=log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "model_acc = deepcopy(model)\n",
    "optimizer.accelerate()\n",
    "optimizer.store_parameters([model_acc.classifier.parameters(), model_acc.features.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc.cuda()\n",
    "train_score = validation(model_acc, train_loader)\n",
    "valid_score = validation(model_acc, valid_loader)\n",
    "model_acc.cpu()\n",
    "\n",
    "print(\"Train:\", train_score)\n",
    "print(\"Valid:\", valid_score)\n",
    "print(\"Train:\", train_score, flush=True, file=log_file)\n",
    "print(\"Valid:\", valid_score, flush=True, file=log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-definition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
